{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3a84b3",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>T-SNE + Spectal Clustering</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e71c9",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65503e",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist,fashion_mnist\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "from scipy.linalg import eig\n",
    "cores = multiprocessing.cpu_count()-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1939e0",
   "metadata": {},
   "source": [
    "## Data Loading & Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454d70f",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that gives us information about data shapes and reshapes the data in order to be suitable for our models.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b7726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(x_train,y_train,x_test,y_test,data_name):\n",
    "    print ('Basic informations:')\n",
    "    print('X_train: ' + str(x_train.shape))\n",
    "    print('Y_train: ' + str(y_train.shape))\n",
    "    print('X_test:  ' + str(x_test.shape))\n",
    "    print('Y_test:  ' + str(y_test.shape))\n",
    "    x_train = x_train.reshape(x_train.shape[0], np.prod(x_train.shape[1:])) \n",
    "    x_test = x_test.reshape(x_test.shape[0], np.prod(x_test.shape[1:]))  \n",
    "    # Change integers to 32-bit floating point numbers\n",
    "    x_train = x_train.astype('float32')   \n",
    "    x_test = x_test.astype('float32')\n",
    "    print(\"\\nData shapes after reshaping:\")\n",
    "    print(\"Training matrix shape\", x_train.shape)\n",
    "    print(\"Testing matrix shape\", x_test.shape)\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32303139",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that provides us with the input data:\n",
    "<ol>\n",
    "<li>Load the necessary data according to the give to the given data name.</li>\n",
    "<li>Create a subset for each data according to the given data sizes (If subset variable = 'True\").</li>\n",
    "<li>Use the above function and returns the reshaped data.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580479db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(subset,data_name,train_subset_size,test_subset_size):\n",
    "    if data_name == 'Mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    elif data_name == 'FashionMnist':\n",
    "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    if subset:\n",
    "        x_train,y_train,x_test,y_test = x_train[:train_subset_size],y_train[:train_subset_size],x_test[:test_subset_size],y_test[:test_subset_size]\n",
    "        x_train,y_train,x_test,y_test = data_reshape(x_train,y_train,x_test,y_test,data_name)\n",
    "    else:\n",
    "        x_train,y_train,x_test,y_test = data_reshape(x_train,y_train,x_test,y_test,data_name)\n",
    "        \n",
    "    return x_train,y_train,x_test,y_test   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c4088",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that applies standardization on the given data and returns it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ff5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalling(x_train,x_test):\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    x_test = StandardScaler().fit_transform(x_test)\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78021b30",
   "metadata": {},
   "source": [
    "## T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f2a53",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that applies dimensionality reduction using the T-SNE algorithm (n_components=2) on the given data and returns the embedding of the data in low-dimensional space.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tsne(data):\n",
    "    tsne = TSNE(n_components=2,random_state=0,n_jobs=cores)\n",
    "    result = tsne.fit_transform(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf321ff3",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that applies dimensionality reduction using the PCA algorithm on the given data and returns the transformed values.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data,n_comp):\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    results = pca.fit_transform(data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee409a8d",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that prints and saves a plot which consists of 3 Scatterplot:\n",
    "<ol>\n",
    "<li>Scatterplot with the x and y calculated by Pca (n_components =2).</li>\n",
    "<li>Scatterplot with the x and y calculated by TSNE (n_components =2).</li>\n",
    "<li>Scatterplot with the x and y calculated by Pca (n_components = 50) + TSNE (n_components =2).</li>\n",
    "    \n",
    "In all cases, the plotted labels are the real data labels\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df79f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reduction_results(pca_res,tsne_res,pca_tsne_res,y_train,data_name,helper_pca_n_comp):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "    fig.suptitle('{}: Dimensionality Reduction Approaches'.format(data_name), fontsize=15)\n",
    "    font_size = {'fontsize': 12}\n",
    "\n",
    "    sns.scatterplot(ax=axes[0], x = pca_res[:,0], y = pca_res[:,1], hue = y_train, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[0].set_title('PCA (n=2)',fontdict = font_size)\n",
    "\n",
    "    sns.scatterplot(ax=axes[1], x = tsne_res[:,0], y = tsne_res[:,1], hue = y_train, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[1].set_title('T-SNE (n=2)',fontdict = font_size)\n",
    "\n",
    "    sns.scatterplot(ax=axes[2], x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = y_train, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[2].set_title('PCA (n={}) + T-SNE (n=2)'.format(helper_pca_n_comp),fontdict = font_size)\n",
    "    plt.savefig('Exports/TSNE_' + data_name + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe2315",
   "metadata": {},
   "source": [
    " <font size=\"3\">\n",
    "A function that applies the following steps:\n",
    "<ol>\n",
    "<li>Apply Pca (n_components =2).</li>\n",
    "<li>Apply TSNE (n_components =2).</li>\n",
    "<li>Apply Pca (n_components = 50) and then apply TSNE (n_components =2).</li>\n",
    "<li>Return the result of PCA+TSNE because they are the input for spectral computations.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_pipeline(x_train,y_train,helper_pca_n_comp,data_name):\n",
    "    pca_res = apply_pca(x_train,2)\n",
    "    tsne_res = apply_tsne(x_train)\n",
    "    helper_pca = apply_pca(x_train,helper_pca_n_comp)\n",
    "    pca_tsne_res = apply_tsne(helper_pca)\n",
    "    plot_reduction_results(pca_res,tsne_res,pca_tsne_res,y_train,data_name,helper_pca_n_comp)\n",
    "    del(pca_res)\n",
    "    del(tsne_res)\n",
    "    return pca_tsne_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123621a",
   "metadata": {},
   "source": [
    "## Computing Eigenvalues and Eigenvectors Using Spectral Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be6761",
   "metadata": {},
   "source": [
    " <font size=\"3\">\n",
    "A function that applies spectral computations with the following steps:\n",
    "<ol>\n",
    "<li>It computes the pairwise distances between the rows of the data matrix using the Euclidean distance metric. This computation is done in parallel using the specified number of cores.</li>\n",
    "<li>It converts the pairwise distances matrix into a matrix of 0s and 1s, where 1s indicate distances less than the distance threshold and 0s indicate distances greater than or equal to the threshold.</li>\n",
    "<li>It calculates the Laplacian matrix from the 0/1 matrix using the formula L = D - W, where D is the diagonal matrix of row sums of W and W is the 0/1 matrix.</li>\n",
    "<li>It computes the eigenvalues and eigenvectors of the Laplacian matrix using the eig() function.</li>\n",
    "<li>It returns the eigenvalues and eigenvectors.</li>\n",
    "   \n",
    "    ps: This function have designed for Mnist dataset. We make experiments and we find that using a threshold we achieve better results.  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37747a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_computation_mnist(data,cores,distance_threshold):\n",
    "    start = dt.now()\n",
    "    W = pairwise_distances(data, metric=\"euclidean\", n_jobs=cores)\n",
    "    vectorizer = np.vectorize(lambda x: 1 if x < distance_threshold else 0)\n",
    "    W = np.vectorize(vectorizer)(W)\n",
    "    print(f\"\\nW with shape {W.shape} :\")\n",
    "    print(W)\n",
    "    D = np.diag(np.sum(np.array(W), axis=1))\n",
    "    print(f\"\\nDegree Matrix with shape {D.shape} :\")\n",
    "    print(D)\n",
    "    L = D - W\n",
    "    del(D)\n",
    "    del(W)\n",
    "    print(f\"\\nLaplacian Matrix with shape {L.shape} :\")\n",
    "    print(L)\n",
    "    eigval, eigvec = eig(L)\n",
    "    del(L)\n",
    "    print (f\"\\nEigen Values have been computed at {(dt.now() - start).seconds} seconds\")\n",
    "    print(f\"Eigenvalues Matrix with shape {eigval.shape} :\")\n",
    "    print(f\"Eigenvectors Matrix with shape {eigvec.shape} :\")\n",
    "    return eigval,eigvec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f19a1",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that applies spectral computations with the following steps:\n",
    "<ol>\n",
    "<li>Compute the pairwise distances between the data points using the Euclidean distance metric and the specified number of cores.</li>\n",
    "<li>Compute the kernel matrix (K) of the pairwise distances using a Gaussian (rbf) kernel.</li>\n",
    "<li>Compute the diagonal matrix (D) using the kernel matrix.</li>\n",
    "<li>Compute the Laplacian matrix (L) using the kernel and diagonal matrices.</li>\n",
    "<li>Compute the eigenvalues and eigenvectors of the Laplacian matrix.</li>\n",
    "<li>Return the eigenvalues and eigenvectors.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52adf04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_computation_fashion_mnist(data,cores,sigma):\n",
    "    start = dt.now()\n",
    "    W = pairwise_distances(data, metric=\"euclidean\", n_jobs=cores)\n",
    "    print(W)\n",
    "    K = np.exp(-W**2 / (2 * sigma**2))\n",
    "    print(f\"\\nK with shape {K.shape} :\")\n",
    "    print(K)\n",
    "    D = np.diag(np.sum(K, axis=1))\n",
    "    print(f\"\\nDegree Matrix with shape {D.shape} :\")\n",
    "    print(D)\n",
    "    L = D - K\n",
    "    del(D)\n",
    "    del(K)\n",
    "    print(f\"\\nLaplacian Matrix with shape {L.shape} :\")\n",
    "    print(L)\n",
    "    eigval, eigvec = eig(L)\n",
    "    del(L)\n",
    "    print (f\"\\nEigen Values have been computed at {(dt.now() - start).seconds} seconds\")\n",
    "    print(f\"Eigenvalues Matrix with shape {eigval.shape} :\")\n",
    "    print(f\"Eigenvectors Matrix with shape {eigvec.shape} :\")\n",
    "    return eigval,eigvec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8dd60",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that preprocess the eigenvectors with the followin steps:\n",
    "<ol>\n",
    "<li>If the keep_real argument is True, it keeps only the real part of the eigenvalues and eigenvectors. If it is False, it keeps only the imaginary part.</li>\n",
    "<li>It sorts the eigenvalues and keeps the indices of the first n_comp_egenvec eigenvalues.</li>\n",
    "<li>It creates a Pandas dataframe from the eigenvectors and selects only the columns corresponding to the indices of the smallest eigenvalues(eigenvectors corresponding to zero eigenvalues are not included).</li>\n",
    "<li>It converts the dataframe back to a NumPy array and scales the data using StandardScaler.</li>\n",
    "<li>It returns the scaled eigenvectors and the indices of the best eigenvalues.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_egenvectors(eigval,eigvec,n_comp_egenvec,keep_real):\n",
    "    if keep_real:\n",
    "        eigval, eigvec = eigval.real, eigvec.real\n",
    "    else:\n",
    "        eigval, eigvec = eigval.imag, eigvec.imag      \n",
    "    best_egenval_idx = sorted(range(len(eigval)), key = lambda sub: eigval[sub])\n",
    "    print \n",
    "    best_egenval_idx = best_egenval_idx[2:n_comp_egenvec+2]\n",
    "    df_egenvec = pd.DataFrame(eigvec)\n",
    "    df_egenvec = df_egenvec[best_egenval_idx]\n",
    "    new_eigvec = np.array(df_egenvec)\n",
    "    new_eigvec = StandardScaler().fit_transform(new_eigvec)\n",
    "    return new_eigvec,best_egenval_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5602db",
   "metadata": {},
   "source": [
    "## K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510e5d5",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that apply K-mean algorithm from scratch:\n",
    "<ol>\n",
    "<li>The function takes two arguments: k and features. k is the number of clusters to create, and features is a NumPy array of data points.</li>\n",
    "<li>It initializes the centroids of the clusters using the k-means++ algorithm. This involves randomly selecting one centroid from the data points and then selecting the remaining centroids using a probability distribution based on the distances of the data points to the nearest centroid.</li>\n",
    "<li>It assigns each data point to the cluster with the nearest centroid.</li>\n",
    "<li>It computes the mean of the points in each cluster to get the new centroids.</li>\n",
    "<li>It repeats the process of assigning points to clusters and computing new centroids until convergence, which occurs when the centroids do not change from one iteration to the next.</li>\n",
    "<li>It returns the final centroids and a list of cluster assignments for each data point.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k: int, features: np.ndarray) -> Tuple[List[List[float]], List[int]]:\n",
    "    \n",
    "    def euclidean_distance(p1: np.ndarray, p2: np.ndarray) -> float:\n",
    "        return np.linalg.norm(p1 - p2)\n",
    "\n",
    "    def mean(points: np.ndarray) -> np.ndarray:\n",
    "        return np.mean(points, axis=0)\n",
    "\n",
    "    # Step 1: Initialize centroids using k-means++\n",
    "    num_features = features.shape[0]\n",
    "    centroids = []\n",
    "    centroids.append(features[random.choice(range(num_features))])\n",
    "    for _ in range(k - 1):\n",
    "        distances = [min([euclidean_distance(point, centroid) for centroid in centroids]) for point in features]\n",
    "        total_distance = sum(distances)\n",
    "        probabilities = [distance / total_distance for distance in distances]\n",
    "        centroids.append(features[np.random.choice(range(num_features), p=probabilities)])\n",
    "\n",
    "    # Step 2: Assign points to closest centroid\n",
    "    clusters = [[] for _ in range(k)]\n",
    "    for i in range(num_features):\n",
    "        point = features[i]\n",
    "        centroids_array = np.array(centroids)\n",
    "        distances = [euclidean_distance(point, centroid) for centroid in centroids_array]\n",
    "        cluster_index = distances.index(min(distances))\n",
    "        clusters[cluster_index].append(point)\n",
    "\n",
    "    # Step 3: Recompute centroids\n",
    "    new_centroids = []\n",
    "    for cluster in clusters:\n",
    "        new_centroids.append(mean(cluster))\n",
    "\n",
    "    # Step 4: Repeat steps 2 and 3 until convergence\n",
    "    while not np.array_equal(centroids, new_centroids):\n",
    "        centroids = new_centroids\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        for i in range(num_features):\n",
    "            point = features[i]\n",
    "            centroids_array = np.array(centroids)\n",
    "            distances = [euclidean_distance(point, centroid) for centroid in centroids_array]\n",
    "            cluster_index = distances.index(min(distances))\n",
    "            clusters[cluster_index].append(point)\n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroids.append(mean(cluster))\n",
    "\n",
    "    # Step 5: Assign points to final clusters\n",
    "    cluster_assignments = []\n",
    "    for i in range(num_features):\n",
    "        point = features[i]\n",
    "        centroids_array = np.array(centroids)\n",
    "        distances = [euclidean_distance(point, centroid) for centroid in centroids_array]\n",
    "        cluster_index = distances.index(min(distances))\n",
    "        cluster_assignments.append(cluster_index)\n",
    "\n",
    "    return new_centroids, cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1763880",
   "metadata": {},
   "source": [
    "## Clustering Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c0383",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that merges the above functions to provide us with the final clustering results.\n",
    "<ol>\n",
    "<li>It takes as input the eigenvalues and the eigenvectors.</li>\n",
    "<li>It keeps only the necessary eigenvectors.</li>\n",
    "<li>It chooses proposed K-Mean or Sklearn K-Mean according to the given variable (we do this to compare our algorithm with that of Sklearn).</li>\n",
    "<li>It uses K-means and takes the clustering results.</li>\n",
    "<li>It Computes the silhouette metric.</li>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a291ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,k,kmeans_mode):\n",
    "    start = dt.now()\n",
    "    eigvec,best_egenval_idx = reduce_egenvectors(eigval,eigvec,n_comp_egenvec,True)\n",
    "    data_input = eigvec.reshape(eigvec.shape[0], -1)\n",
    "    \n",
    "    if kmeans_mode == 'Proposed':\n",
    "        centroids, cluster_assignments = kmeans(k,data_input)\n",
    "        print (f\"\\nProposed K-means computations have been finished successfully at {(dt.now() - start).seconds} seconds\")\n",
    "    elif kmeans_mode == 'Sklearn':    \n",
    "        k_means = KMeans(init='k-means++', n_clusters=k, max_iter=1000)\n",
    "        km_clustering = k_means.fit(data_input)\n",
    "        cluster_assignments = km_clustering.labels_\n",
    "        centroids = km_clustering.cluster_centers_\n",
    "        print (f\"\\nSklearn K-means computations have been finished successfully at {(dt.now() - start).seconds} seconds\")\n",
    "    silhouette = silhouette_score(data_input,cluster_assignments)  \n",
    "    return cluster_assignments,silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763493e6",
   "metadata": {},
   "source": [
    "<font size=\"3\">  \n",
    "A function that applies SpectralClustering algorithm from the Sklearn library. We do this to compare our algorithm with that of Sklearn\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47311407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_pipeline(pca_tsne_res,k):\n",
    "    start = dt.now()\n",
    "    pca_tsne_res = StandardScaler().fit_transform(pca_tsne_res)\n",
    "    sp_cl = SpectralClustering(n_clusters=k, affinity='rbf', random_state=42)\n",
    "    spectral_clustering = sp_cl.fit(pca_tsne_res)\n",
    "    cluster_assignments = spectral_clustering.labels_\n",
    "    silhouette = silhouette_score(pca_tsne_res,cluster_assignments)\n",
    "    print (f\"\\nSpectral Clustering of Sklearn has been finished successfully at {(dt.now() - start).seconds} seconds\")\n",
    "    return cluster_assignments,silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf4d71",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that prints and saves a plot which consists of 4 Scatterplot to compare our algorithm with that of Sklearn:\n",
    "<ol>\n",
    "<li>Scatterplot with the real labels as clusters.</li>\n",
    "<li>Scatterplot with the cluster results of our implementations of Spectral Computations and K-means.</li>\n",
    "<li>Scatterplot with the cluster results of our implementations of Spectral computation and Sklearn K-means</li>\n",
    "<li>Scatterplot with the cluster results of our Sklearn Spectral Clustering</li>   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_results(pca_tsne_res,y_train,our_cluster_assignments,km_sklearn_cluster_assignments,full_sklearn_cluster_assignments,data_name):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 8), sharey=True)\n",
    "    fig.suptitle('{}: Spektral Clustering Approaches (Clusters = 10)'.format(data_name), fontsize=20)\n",
    "    font_size = {'fontsize': 17}\n",
    "    \n",
    "    sns.scatterplot(ax=axes[0][0],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = y_train, \n",
    "                palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[0][0].set_title('Real Clusters',fontdict = font_size)\n",
    "\n",
    "    sns.scatterplot(ax=axes[0][1], x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = our_cluster_assignments, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[0][1].set_title('Proposed Method',fontdict = font_size)\n",
    "\n",
    "    sns.scatterplot(ax=axes[1][0], x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = km_sklearn_cluster_assignments, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[1][0].set_title('Proposed Spectral + Sklearn K-means',fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[1][1], x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = full_sklearn_cluster_assignments, \n",
    "                    palette = sns.hls_palette(10), legend = 'full')\n",
    "    axes[1][1].set_title('Full Sklearn Spectral Clustering',fontdict = font_size)\n",
    "    plt.savefig('Exports/Spectral_Clustering_Aproaches_' + data_name + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c34f80",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "This function performs a series of experiments where spectral clustering is applied ussing different number of clusters on each experiment.\n",
    "\n",
    "    \n",
    "The function performs a loop over the values in n_clusters. For each value of n, the function performs spectral clustering using the proposed_pipeline function, with the specified number of clusters (n), and the other input arguments. \n",
    "    \n",
    "The output of proposed_pipeline is a tuple containing the cluster assignments and the silhouette score for each experiment.\n",
    "The function stores the cluster assignments in a list called all_results.\n",
    "After the loop is finished, the function returns the list all_results, which contains the cluster assignments for all of the experiments.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_experiments(eigval,eigvec,cores,n_clusters,n_comp_egenvec):\n",
    "    all_results = []\n",
    "    for n in n_clusters:\n",
    "        cluster_assignments,silhouette = proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,n,'Proposed')\n",
    "        all_results.append(cluster_assignments) \n",
    "    return all_results    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c6f38",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "A function that prints and saves a plot which consists of 9 Scatterplot that observe the clustering behavior on different numbers of clusters. Each subplot depicts the clustering results for a specific number of clusters.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_differen_clusters(k_list,all_results,data_name):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(30, 12), sharey=True)\n",
    "    fig.suptitle('{}: Experiments with different number of K'.format(data_name), fontsize=25)\n",
    "    font_size = {'fontsize': 20}\n",
    "    \n",
    "    sns.scatterplot(ax=axes[0][0],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[0], \n",
    "                palette = sns.hls_palette(k_list[0]), legend = 'full')\n",
    "    axes[0][0].set_title('K = {}'.format(k_list[0]),fontdict = font_size)\n",
    "\n",
    "    sns.scatterplot(ax=axes[0][1],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[1], \n",
    "                palette = sns.hls_palette(k_list[1]), legend = 'full')\n",
    "    axes[0][1].set_title('K = {}'.format(k_list[1]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[0][2],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[2], \n",
    "                palette = sns.hls_palette(k_list[2]), legend = 'full')\n",
    "    axes[0][2].set_title('K = {}'.format(k_list[2]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[1][0],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[3], \n",
    "                palette = sns.hls_palette(k_list[3]), legend = 'full')\n",
    "    axes[1][0].set_title('K = {}'.format(k_list[3]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[1][1],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[4], \n",
    "                palette = sns.hls_palette(k_list[4]), legend = 'full')\n",
    "    axes[1][1].set_title('K = {}'.format(k_list[4]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[1][2],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[5], \n",
    "                palette = sns.hls_palette(k_list[5]), legend = 'full')\n",
    "    axes[1][2].set_title('K = {}'.format(k_list[5]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[2][0],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[6], \n",
    "                palette = sns.hls_palette(k_list[6]), legend = 'full')\n",
    "    axes[2][0].set_title('K = {}'.format(k_list[6]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[2][1],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[7], \n",
    "                palette = sns.hls_palette(k_list[7]), legend = 'full')\n",
    "    axes[2][1].set_title('K = {}'.format(k_list[7]),fontdict = font_size)\n",
    "    \n",
    "    sns.scatterplot(ax=axes[2][2],x = pca_tsne_res[:,0], y = pca_tsne_res[:,1], hue = all_results[8], \n",
    "                palette = sns.hls_palette(k_list[8]), legend = 'full')\n",
    "    axes[2][2].set_title('K = {}'.format(k_list[8]),fontdict = font_size)\n",
    "    plt.savefig('Exports/K-Experiments_' + data_name + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f24a97",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d4402",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "In the following cells we use the above functions to apply spectral clustering to the Mnist-dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16409a",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f99969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Mnist'\n",
    "train_subset_size = 15000\n",
    "test_subset_size = 2000\n",
    "distance_threshold = 5\n",
    "helper_pca_n_comp = 50\n",
    "k = 10\n",
    "different_k = np.arange(8,17,1)\n",
    "n_comp_egenvec = k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dcc8c",
   "metadata": {},
   "source": [
    "### Data Loading, Preprocessing, T-sne, and Eigenvectors computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test  = data_load(True,data_name,train_subset_size,test_subset_size)\n",
    "x_train,x_test = scalling(x_train,x_test)\n",
    "pca_tsne_res = tsne_pipeline(x_train,y_train,helper_pca_n_comp,data_name)\n",
    "eigval,eigvec = spectral_computation_mnist(pca_tsne_res,cores,distance_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67999322",
   "metadata": {},
   "source": [
    "### Spectral Clustering using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cluster_assignments,our_silhouette = proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,k,\n",
    "                                                           kmeans_mode='Proposed')\n",
    "\n",
    "km_sklearn_cluster_assignments,km_sklearn_silhouette = proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,\n",
    "                                                                         k,kmeans_mode='Sklearn')\n",
    "\n",
    "full_sklearn_cluster_assignments,full_sklearn_silhouette = sklearn_pipeline(pca_tsne_res,k)\n",
    "\n",
    "plot_cluster_results(pca_tsne_res,y_train,our_cluster_assignments,km_sklearn_cluster_assignments,\n",
    "                     full_sklearn_cluster_assignments,data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d8562",
   "metadata": {},
   "source": [
    "### Silhouette metric on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d68202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proposed Method Silhouette: ',our_silhouette)\n",
    "print('K-Means Sklearn Silhouette: ',km_sklearn_silhouette)\n",
    "print('Spectral Clustering Sklearn Silhouette: ',full_sklearn_silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d77951",
   "metadata": {},
   "source": [
    "### Spectral Clustering using different number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = k_experiments(eigval,eigvec,cores,different_k,n_comp_egenvec)\n",
    "plot_differen_clusters(different_k,all_results,data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cadf2",
   "metadata": {},
   "source": [
    "## FashionMnist Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67571c",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "In the following cells we use the above functions to apply spectral clustering to the Mnist-dataset.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6239a",
   "metadata": {},
   "source": [
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eeef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_name = 'FashionMnist'\n",
    "train_subset_size = 15000\n",
    "test_subset_size = 2000\n",
    "sigma = 1\n",
    "helper_pca_n_comp = 200\n",
    "k = 10\n",
    "different_k = np.arange(4,13,1)\n",
    "n_comp_egenvec = k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa969c72",
   "metadata": {},
   "source": [
    "### Data Loading, Preprocessing, T-sne, and Eigenvectors computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fed2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test  = data_load(True,data2_name,train_subset_size,test_subset_size)\n",
    "x_train,x_test = scalling(x_train,x_test)\n",
    "pca_tsne_res = tsne_pipeline(x_train,y_train,helper_pca_n_comp,data2_name)\n",
    "eigval,eigvec = spectral_computation_fashion_mnist(pca_tsne_res,cores,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5469ea4",
   "metadata": {},
   "source": [
    "### Spectral Clustering using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cluster_assignments,our_silhouette = proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,k,\n",
    "                                                           kmeans_mode='Proposed')\n",
    "\n",
    "km_sklearn_cluster_assignments,km_sklearn_silhouette = proposed_pipeline(eigval,eigvec,cores,n_comp_egenvec,\n",
    "                                                                         k,kmeans_mode='Sklearn')\n",
    "\n",
    "full_sklearn_cluster_assignments,full_sklearn_silhouette = sklearn_pipeline(pca_tsne_res,k)\n",
    "\n",
    "plot_cluster_results(pca_tsne_res,y_train,our_cluster_assignments,km_sklearn_cluster_assignments,\n",
    "                     full_sklearn_cluster_assignments,data2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f705a",
   "metadata": {},
   "source": [
    "### Silhouette metric on Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proposed Method Silhouette: ',our_silhouette)\n",
    "print('K-Means Sklearn Silhouette: ',km_sklearn_silhouette)\n",
    "print('Spectral Clustering Sklearn Silhouette: ',full_sklearn_silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19184cf5",
   "metadata": {},
   "source": [
    "### Spectral Clustering using different number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57935dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = k_experiments(eigval,eigvec,cores,different_k,n_comp_egenvec)\n",
    "plot_differen_clusters(different_k,all_results,data2_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
